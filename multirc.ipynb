{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1253ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "import inspect\n",
    "import code\n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import cross_entropy, log_softmax\n",
    "\n",
    "import datasets\n",
    "from util import const, icl, lm, infogain, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4a45aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util.infogain' from '/mmfs1/gscratch/zlab/ahai/repo/infogain/util/infogain.py'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(infogain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "73e7da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = type('', (), {})()\n",
    "# parser.add_argument('out_file', type=str)\n",
    "# args.out_file = NotImplemented\n",
    "# parser.add_argument('--n_tries', type=int, default=10)\n",
    "args.n_tries = NotImplemented\n",
    "# parser.add_argument('--p', type=float, default=0.5)\n",
    "args.p = NotImplemented\n",
    "# parser.add_argument('--gen_len', type=int, default=50)\n",
    "args.gen_len = NotImplemented\n",
    "# parser.add_argument('--model', type=str, default='n125m')\n",
    "args.model = '2l'\n",
    "# parser.add_argument('--n_demos', type=int, default=10)\n",
    "args.n_demos = NotImplemented\n",
    "# parser.add_argument('--n_gen_bs', type=int, default=10)\n",
    "args.n_gen_bs = NotImplemented\n",
    "# parser.add_argument('--device', type=str, default='cuda')\n",
    "args.device = 'cuda'\n",
    "# parser.add_argument('--seed', type=int, default=0)\n",
    "args.seed = 0\n",
    "# parser.add_argument('--worker_id', type=int, default=None)\n",
    "args.worker_id = NotImplemented\n",
    "# parser.add_argument('--n_shards', type=int, default=None)\n",
    "args.n_shards = NotImplemented\n",
    "# parser.add_argument('--print_int', type=int, default=1)\n",
    "args.print_int = NotImplemented\n",
    "# parser.add_argument('--override', action='store_true')\n",
    "args.override = NotImplemented\n",
    "\n",
    "# if args.override:\n",
    "#     with open(args.out_file, 'w') as out:\n",
    "#         pass\n",
    "# else:\n",
    "#     assert(not os.path.exists(args.out_file))\n",
    "\n",
    "util.set_all_seeds(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4a486b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer, cw_length = lm.load(args.model, args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8147553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/multirc/dev.json') as f:\n",
    "  data = json.load(f)['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "48e1f4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util.infogain' from '/mmfs1/gscratch/zlab/ahai/repo/infogain/util/infogain.py'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(infogain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9dde3a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  all_lls = []\n",
    "  pres, recs = [], []\n",
    "  for datum_idx, datum in enumerate(data):\n",
    "    print(datum_idx)\n",
    "    datum = datum['paragraph']\n",
    "    passage_text = datum['text']\n",
    "    passage_ids = tokenizer('\\n' + passage_text.strip()).input_ids\n",
    "    datum_lls = []\n",
    "    for question in datum['questions']:\n",
    "      true_positives, pred_positives, correct = 0, 0, 0\n",
    "      question_text = question['question']\n",
    "      answers = question['answers']\n",
    "      tests = multirc_make_tests(question_text, [a['text'] for a in answers])\n",
    "      question_lls = []\n",
    "      for answer, test_tuple in zip(answers, tests):\n",
    "        tests = [test_tuple[0]] + test_tuple[1]\n",
    "        test_ids = [ tokenizer(test).input_ids for test in tests ]\n",
    "        pad_lens = infogain.get_pad_lens(test_ids)\n",
    "        for test_idx in range(len(test_ids)):\n",
    "          test_ids[test_idx] += passage_ids + [0]*pad_lens[test_idx]\n",
    "        tests_t = torch.LongTensor(test_ids).to(args.device)\n",
    "        result = model(tests_t)\n",
    "        token_lls = cross_entropy(result.logits[:, :-1].transpose(1,2), tests_t[:, 1:], reduction='none').mul(-1)\n",
    "        lls = [ l[-len(passage_ids)-pad_lens[i]:-pad_lens[i]].sum().item() for i, l in enumerate(token_lls) ]\n",
    "        if lls[0]-lls[1] > 0 and lls[0]-lls[2] > 0:\n",
    "          pred = True\n",
    "        else:\n",
    "          pred = False\n",
    "        pred_positives += pred\n",
    "        true_positives += answer['isAnswer']\n",
    "        correct += pred and answer['isAnswer']\n",
    "        question_lls.append(lls)\n",
    "      if true_positives > 0:\n",
    "        pre = correct / pred_positives if pred_positives > 0 else 0\n",
    "        rec = correct / true_positives\n",
    "      else:\n",
    "        pre, rec = 1, 1\n",
    "      pres.append(pre)\n",
    "      recs.append(rec)\n",
    "      datum_lls.append(question_lls)\n",
    "    all_lls.append(datum_lls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a959687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(l):\n",
    "  return sum(l) / len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2b39fce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4884700444330475"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * (avg(pres) * avg(recs)) / (avg(pres) + avg(recs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "726a5dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(10)[-9:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcac5fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'e2e_gen_tests',\n",
       " 'get_pad_lens',\n",
       " 'multirc_make_tests',\n",
       " 'multirc_proc_passage',\n",
       " 'random',\n",
       " 're']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(infogain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4a8fa334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013432179816765654\n",
      "0.1568466289168926\n",
      "0.3941507296769915\n",
      "0.5041326290812322\n",
      "0.5586778170777598\n",
      "0.5851905495119936\n",
      "0.598158998274806\n",
      "0.6011063777309774\n",
      "0.606431049473297\n",
      "0.608496633088301\n",
      "0.6102838757657123\n",
      "0.6103828897550012\n",
      "0.6107981409872096\n",
      "0.6121160912774928\n",
      "0.6122779667982298\n",
      "0.6122779667982298\n",
      "0.6123973692330503\n",
      "0.6123973692330503\n",
      "0.6123973692330503\n",
      "0.6127964690511252\n",
      "0.6127964690511252\n",
      "0.6127964690511252\n",
      "0.6130464512432885\n",
      "0.6130464512432885\n",
      "0.6130464512432885\n",
      "0.6130464512432885\n",
      "0.6130464512432885\n",
      "0.6130464512432885\n",
      "0.6130464512432885\n",
      "0.6130464512432885\n",
      "0.6130464512432885\n",
      "0.6130464512432885\n",
      "0.6130464512432885\n",
      "0.6130464512432885\n",
      "0.6130464512432885\n",
      "0.6130464512432885\n",
      "0.6130464512432885\n",
      "0.6130464512432885\n",
      "0.6130464512432885\n",
      "0.6130464512432885\n"
     ]
    }
   ],
   "source": [
    "for threshold in range(0, 400, 10):\n",
    "  with torch.no_grad():\n",
    "    pres, recs = [], []\n",
    "    acc = []\n",
    "    for datum_idx, datum in enumerate(data):\n",
    "      datum = datum['paragraph']\n",
    "      passage_text = datum['text']\n",
    "      passage_ids = tokenizer('\\n' + passage_text.strip()).input_ids\n",
    "      datum_lls = all_lls[datum_idx]\n",
    "      for question_idx, question in enumerate(datum['questions']):\n",
    "        true_positives, pred_positives, correct = 0, 0, 0\n",
    "        question_text = question['question']\n",
    "        answers = question['answers']\n",
    "        tests = multirc_make_tests(question_text, [a['text'] for a in answers])\n",
    "        question_lls = datum_lls[question_idx]\n",
    "        all_right = True\n",
    "        for answer_idx, (answer, test_tuple) in enumerate(zip(answers, tests)):\n",
    "          answer_lls = question_lls[answer_idx]\n",
    "          pred =  (answer_lls[0] - answer_lls[1] < threshold) and (answer_lls[0] - answer_lls[2] < threshold)\n",
    "          #pred = (answer_lls[0] - answer_lls[2] > threshold)\n",
    "          pred_positives += pred\n",
    "          true_positives += answer['isAnswer']\n",
    "          correct += pred and answer['isAnswer']\n",
    "          all_right = all_right and (pred == answer['isAnswer'])\n",
    "        acc.append(all_right)\n",
    "        if true_positives > 0:\n",
    "          pre = correct / pred_positives if pred_positives > 0 else 0\n",
    "          rec = correct / true_positives\n",
    "        else:\n",
    "          pre, rec = 1, 1\n",
    "        pres.append(pre)\n",
    "        recs.append(rec)\n",
    "  print(2 * (avg(pres) * avg(recs)) / (avg(pres) + avg(recs)))\n",
    "  # print(avg(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "40ac8554",
   "metadata": {},
   "outputs": [],
   "source": [
    "n125m_lls = all_lls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4d368aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "94aa7b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.02040816, 0.04081633, 0.06122449, 0.08163265,\n",
       "       0.10204082, 0.12244898, 0.14285714, 0.16326531, 0.18367347,\n",
       "       0.20408163, 0.2244898 , 0.24489796, 0.26530612, 0.28571429,\n",
       "       0.30612245, 0.32653061, 0.34693878, 0.36734694, 0.3877551 ,\n",
       "       0.40816327, 0.42857143, 0.44897959, 0.46938776, 0.48979592,\n",
       "       0.51020408, 0.53061224, 0.55102041, 0.57142857, 0.59183673,\n",
       "       0.6122449 , 0.63265306, 0.65306122, 0.67346939, 0.69387755,\n",
       "       0.71428571, 0.73469388, 0.75510204, 0.7755102 , 0.79591837,\n",
       "       0.81632653, 0.83673469, 0.85714286, 0.87755102, 0.89795918,\n",
       "       0.91836735, 0.93877551, 0.95918367, 0.97959184, 1.        ])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0,1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1ab6b2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6211819389110226\n",
      "0.621630615640599\n",
      "0.6219552886219554\n",
      "0.6221776216758655\n",
      "0.6225432555014279\n",
      "0.6230834035383319\n",
      "0.6236704372784061\n",
      "0.6242362525458248\n",
      "0.6237876467585503\n",
      "0.6238688748506062\n",
      "0.6245926942205454\n",
      "0.6259463179628355\n",
      "0.6251079260922121\n",
      "0.6251082251082251\n",
      "0.6255215577190543\n",
      "0.6256535378180551\n",
      "0.6256338520720406\n",
      "0.6262272089761571\n",
      "0.6269548409769813\n",
      "0.6278659611992946\n",
      "0.6278740714538379\n",
      "0.6283484122760333\n",
      "0.6278282558346695\n",
      "0.6270096463022509\n",
      "0.62705798138869\n",
      "0.6250898634076204\n",
      "0.624977473418634\n",
      "0.623710407239819\n",
      "0.624136677571792\n",
      "0.6236323851203501\n",
      "0.6233528550512445\n",
      "0.6225895316804408\n",
      "0.6206642066420663\n",
      "0.6213160333642261\n",
      "0.6197654941373534\n",
      "0.6194029850746269\n",
      "0.6194756554307115\n",
      "0.6196653506298176\n",
      "0.6183465458663647\n",
      "0.6179817905918057\n",
      "0.6167619047619047\n",
      "0.6150315547905909\n",
      "0.6145873320537427\n",
      "0.6155029813425659\n",
      "0.6160077145612344\n",
      "0.6165471807789187\n",
      "0.6154743390357699\n",
      "0.6155945419103315\n",
      "0.6141793967880925\n",
      "0.6129095546399843\n"
     ]
    }
   ],
   "source": [
    "#f1a\n",
    "for threshold in np.linspace(-7, -4):\n",
    "  with torch.no_grad():\n",
    "    preds, corrects, grounds = [], [], []\n",
    "    for datum_idx, datum in enumerate(data):\n",
    "      datum = datum['paragraph']\n",
    "      passage_text = datum['text']\n",
    "      passage_ids = tokenizer('\\n' + passage_text.strip()).input_ids\n",
    "      datum_lls = all_lls[datum_idx]\n",
    "      for question_idx, question in enumerate(datum['questions']):\n",
    "        true_positives, pred_positives, correct = 0, 0, 0\n",
    "        question_text = question['question']\n",
    "        answers = question['answers']\n",
    "        tests = multirc_make_tests(question_text, [a['text'] for a in answers])\n",
    "        question_lls = datum_lls[question_idx]\n",
    "        all_right = True\n",
    "        for answer_idx, (answer, test_tuple) in enumerate(zip(answers, tests)):\n",
    "          answer_lls = question_lls[answer_idx]\n",
    "          pred =  (answer_lls[0] - answer_lls[1] > threshold) and (answer_lls[0] - answer_lls[2] > threshold)\n",
    "          #pred = (answer_lls[0] - answer_lls[2] > threshold)\n",
    "          preds.append(pred)\n",
    "          corrects.append(pred == answer['isAnswer'] and answer['isAnswer'])\n",
    "          grounds.append(answer['isAnswer'])\n",
    "  pre = sum(corrects) / sum(preds)\n",
    "  rec = sum(corrects) / sum(grounds)\n",
    "  print(2 * (pre * rec) / (pre + rec))\n",
    "  # print(avg(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cf8196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
